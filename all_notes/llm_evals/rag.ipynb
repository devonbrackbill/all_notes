{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond the Basics of Retrieval for Augmenting Generation\n",
    "\n",
    "https://parlance-labs.com/talks/rag/ben.html\n",
    "\n",
    "RAGatouille: library for RAG.\n",
    "\n",
    "https://github.com/bclavie/RAGatouille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Embeddings\n",
    "\n",
    "* dense embeddings (like OpenAI's `text-ada-002`): a fine baseline, but often fails.\n",
    "* ColBERT (Contextualized Late Interaction over BERT): potentially better approach that generalizes to new or complex domains better than dense embeddings.\n",
    "\n",
    "Why are they called **dense embeddings**?\n",
    "\n",
    "The term “dense embeddings” refers to a type of vector representation in which each item (such as a word, sentence, or document) is mapped to a continuous, high-dimensional vector space. These vectors are “dense” because most of the elements in the vector are non-zero, in contrast to “sparse” representations where most elements are zero.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
